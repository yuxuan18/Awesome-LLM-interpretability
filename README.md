# LLM interpretability

## Applications

Large language models in medicine, NatureMed'23, https://www.nature.com/articles/s41591-023-02448-8

Using Large Language Models in Psychology, Nature Reviews Psychology'23, https://www.nature.com/articles/s44159-023-00241-5

Generative Artificial Intelligence through ChatGPT and Other Large Language Models in Ophthalmology: Clinical Applications and Challenges, Ophthalmology Science'23, https://www.sciencedirect.com/science/article/pii/S2666914523001264

## Surveys

On the Opportunities and Risks of Foundation Models, Arxiv'22, https://arxiv.org/pdf/2108.07258.pdf

Large language models shape and are shaped by society: A survey of arXiv publication patterns, Arxiv'23, https://arxiv.org/pdf/2307.10700.pdf

## Attention Analysis

Attention Is All You Need, NeurIPS'17, https://arxiv.org/pdf/1706.03762.pdf

What Does BERT Look At? An Analysis of BERT's Attention, BlackBoxNLP 2019, https://arxiv.org/pdf/1906.04341.pdf

## Structure of Thoughts

Chain-of-Thought Prompting Elicits Reasoning in Large Language Models, NeurIPS'22, https://arxiv.org/pdf/2201.11903.pdf

Tree of Thoughts: Deliberate Problem Solving with Large Language Models, Arxiv'23, https://arxiv.org/pdf/2305.10601.pdf

Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning, ICLR'23, https://arxiv.org/pdf/2205.09712.pdf

## Local Explanations
 
"Why Should I Trust You?": Explaining the Predictions of Any Classifier, KDD'16, https://arxiv.org/pdf/1602.04938.pdf

Local Interpretation of Transformer Based on Linear Decomposition, ACL'23, https://aclanthology.org/2023.acl-long.572.pdf

## Influence Functions

Explaining Black Box Predictions and Unveiling Data Artifacts through Influence Functions, ACL'20, https://arxiv.org/abs/2005.06676

Studying Large Language Model Generalization with Influence Functions, Arxiv'23, https://arxiv.org/pdf/2308.03296.pdf

## Concept Bottleneck Models

Concept Bottleneck Models, ICML'20, https://arxiv.org/pdf/2007.04612.pdf

Probabilistic Concept Bottleneck Models, ICML'23, https://arxiv.org/pdf/2306.01574.pdf

Language in a Bottle: Language Model Guided Concept Bottlenecks for Interpretable Image Classification, CVPR'23, https://arxiv.org/pdf/2211.11158.pdf

Interpretable Neural-Symbolic Concept Reasoning, ICML'23, https://arxiv.org/pdf/2304.14068.pdf


## Attribution

Axiomatic Attribution for Deep Networks, NeurIPS'17, http://proceedings.mlr.press/v70/sundararajan17a/sundararajan17a.pdf

Model Interpretability and Rationale Extraction by Input Mask Optimization, ACL'23, https://aclanthology.org/2023.findings-acl.867.pdf
